{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils import PrCol\n",
    "from bnn import BNN, BNNDataset\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "Color = PrCol()\n",
    "\n",
    "TRAIN_BNN_LF_FLAG = False\n",
    "TRAIN_BNN_MF_FLAG = False\n",
    "TRAIN_BNN_HF_FLAG = False\n",
    "TRAIN_TL_FLAG = False\n",
    "TRAIN_TL_FT_FLAG = False\n",
    "\n",
    "SAVE_MODEL_FLAG = False\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "dataset_location = \"Dataset/bscw_dataset.csv\"\n",
    "SEP = \";\"\n",
    "input_labels = [\"mach\",\"aoa\"]\n",
    "output_labels = [\"cl\",\"cm\"]\n",
    "fidelity_column_name = \"fidelity\"\n",
    "fidelities = [\"low\",\"mid\",\"cfd\"]\n",
    "\n",
    "study_name = \"BSCW_dataset_1\"\n",
    "model_name_prefix = \"BSCW\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_path = f\"AIModels/{study_name}\"\n",
    "\n",
    "try: os.makedirs(study_path)\n",
    "except FileExistsError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mach</th>\n",
       "      <th>aoa</th>\n",
       "      <th>cl</th>\n",
       "      <th>cm</th>\n",
       "      <th>fidelity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222070</td>\n",
       "      <td>-1.443585e-05</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.248369</td>\n",
       "      <td>4.219838e-06</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275482</td>\n",
       "      <td>-8.271854e-07</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.297021</td>\n",
       "      <td>9.484167e-08</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318354</td>\n",
       "      <td>9.272213e-10</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.251295</td>\n",
       "      <td>-7.164018e-02</td>\n",
       "      <td>cfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0.766</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.386129</td>\n",
       "      <td>-6.008131e-02</td>\n",
       "      <td>cfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0.758</td>\n",
       "      <td>3.109000</td>\n",
       "      <td>0.454622</td>\n",
       "      <td>-5.301218e-02</td>\n",
       "      <td>cfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.771</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.412188</td>\n",
       "      <td>-5.756897e-02</td>\n",
       "      <td>cfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.187753</td>\n",
       "      <td>-6.245669e-02</td>\n",
       "      <td>cfd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mach       aoa        cl            cm fidelity\n",
       "0    0.700  0.000000  0.222070 -1.443585e-05      low\n",
       "1    0.700  0.166667  0.248369  4.219838e-06      low\n",
       "2    0.700  0.333333  0.275482 -8.271854e-07      low\n",
       "3    0.700  0.500000  0.297021  9.484167e-08      low\n",
       "4    0.700  0.666667  0.318354  9.272213e-10      low\n",
       "..     ...       ...       ...           ...      ...\n",
       "724  0.737  0.819000  0.251295 -7.164018e-02      cfd\n",
       "725  0.766  2.300000  0.386129 -6.008131e-02      cfd\n",
       "726  0.758  3.109000  0.454622 -5.301218e-02      cfd\n",
       "727  0.771  2.570000  0.412188 -5.756897e-02      cfd\n",
       "728  0.835  0.246000  0.187753 -6.245669e-02      cfd\n",
       "\n",
       "[729 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_all = pd.read_csv(dataset_location,sep=SEP)\n",
    "display(dataset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lf_denorm = dataset_all[dataset_all[fidelity_column_name] == \"low\"]\n",
    "dataset_mf_denorm = dataset_all[dataset_all[fidelity_column_name] == \"mid\"]\n",
    "dataset_hf_denorm = dataset_all[dataset_all[fidelity_column_name] == \"cfd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalers import MinMaxScaler as MMS\n",
    "\n",
    "scaler = MMS(dataset_all.drop(columns=[fidelity_column_name], inplace=False),interval=(1,2))\n",
    "normalized_datasets = []\n",
    "for fid in fidelities:\n",
    "    dataset_fidelity = dataset_all[dataset_all[fidelity_column_name] == fid]\n",
    "    dataset_fidelity_norm = scaler.scaleDataframe(dataset_fidelity.drop(columns=[fidelity_column_name], inplace=False))\n",
    "    normalized_datasets.append(dataset_fidelity_norm)\n",
    "scaler.save(f\"{model_name_prefix}norm.pkl\", path=study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low: 437 188\n",
      "Mid: 19 29\n",
      "Hig: 5 2 51\n"
     ]
    }
   ],
   "source": [
    "dataset_lf = BNNDataset(normalized_datasets[0],input_labels,output_labels,device=DEVICE)\n",
    "dataset_mf = BNNDataset(normalized_datasets[1],input_labels,output_labels,device=DEVICE)\n",
    "dataset_hf = BNNDataset(normalized_datasets[2],input_labels,output_labels,device=DEVICE)\n",
    "dataset_all = BNNDataset(pd.concat([normalized_datasets[0], normalized_datasets[1], normalized_datasets[2]], axis=0),input_labels,output_labels,device=DEVICE)\n",
    "\n",
    "train_lf, valid_lf = dataset_lf.train_val_split(seed=42)\n",
    "train_mf, valid_mf = dataset_mf.train_val_split(train_size=0.4,seed=42)\n",
    "train_hf, valid_hf, test_hf = dataset_hf.train_val_test_split(train_size=0.06,val_size=0.04,seed=42)\n",
    "max_rows = dataset_hf.data.nlargest(2, ['mach', 'aoa'])\n",
    "train_hf = BNNDataset(pd.concat([train_hf.data,max_rows]),input_labels,output_labels,device=DEVICE)\n",
    "\n",
    "print(\"Low:\", len(train_lf), len(valid_lf))\n",
    "print(\"Mid:\", len(train_mf), len(valid_mf))\n",
    "print(\"Hig:\", len(train_hf), len(valid_hf), len(test_hf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the BNN on Low Fidelity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[\u001b[0mBNN LF\u001b[92m] >> Model Loaded on \u001b[94mcpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{study_path}/{model_name_prefix}_bnn_lf.pt\"\n",
    "\n",
    "bnn_lf_model = BNN(\n",
    "    in_dim=len(input_labels),\n",
    "    out_dim=len(output_labels),\n",
    "    mu = 0,\n",
    "    std = 0.0126,\n",
    "    units = [176,176,144,176,176],\n",
    "    denseOut = False,\n",
    "    dropout = False,\n",
    "    device=DEVICE,\n",
    "    activation=nn.LeakyReLU(),\n",
    "    model_name=\"BNN LF\"\n",
    ")\n",
    "if TRAIN_BNN_LF_FLAG:\n",
    "    bnn_lf_model.train_model(\n",
    "        train_lf,\n",
    "        valid_lf,\n",
    "        patience=150,\n",
    "        n_epochs=5000,\n",
    "        batch_size = 32\n",
    "    )\n",
    "    if SAVE_MODEL_FLAG: bnn_lf_model.save(model_path)\n",
    "else: bnn_lf_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the BNN on Mid Fidelity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[\u001b[0mBNN MF\u001b[92m] >> Model Loaded on \u001b[94mcpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{study_path}/{model_name_prefix}_bnn_mf.pt\"\n",
    "\n",
    "bnn_mf_model = BNN(\n",
    "    in_dim=len(input_labels),\n",
    "    out_dim=len(output_labels),\n",
    "    mu = 0,\n",
    "    std = 0.0526,\n",
    "    units = [160,80],\n",
    "    denseOut = False,\n",
    "    dropout = False,\n",
    "    device=DEVICE,\n",
    "    activation = nn.LeakyReLU(),\n",
    "    model_name = \"BNN MF\"\n",
    ")\n",
    "if TRAIN_BNN_MF_FLAG:\n",
    "    bnn_mf_model.train_model(\n",
    "        train_mf,\n",
    "        valid_mf,\n",
    "        patience=500,\n",
    "        n_epochs=10000,\n",
    "        batch_size = 32\n",
    "    )\n",
    "    if SAVE_MODEL_FLAG: bnn_mf_model.save(model_path)\n",
    "else: bnn_mf_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the BNN on High Fidelity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[\u001b[0mBNN HF\u001b[92m] >> Model Loaded on \u001b[94mcpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{study_path}/{model_name_prefix}_bnn_hf.pt\"\n",
    "\n",
    "bnn_hf_model = BNN(\n",
    "    in_dim=len(input_labels),\n",
    "    out_dim=len(output_labels),\n",
    "    mu = 0,\n",
    "    std = 0.0596,\n",
    "    units = [128,160,176],\n",
    "    denseOut = False,\n",
    "    dropout = False,\n",
    "    device=DEVICE,\n",
    "    activation = nn.LeakyReLU(),\n",
    "    model_name = \"BNN HF\"\n",
    ")\n",
    "if TRAIN_BNN_HF_FLAG:\n",
    "    bnn_hf_model.train_model(\n",
    "        train_hf,\n",
    "        valid_hf,\n",
    "        patience=1000,\n",
    "        n_epochs=100000,\n",
    "        batch_size = 32\n",
    "    )\n",
    "    if SAVE_MODEL_FLAG: bnn_hf_model.save(model_path)\n",
    "else: bnn_hf_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[\u001b[0mBNN TL\u001b[92m] >> Model Loaded on \u001b[94mcpu\u001b[0m\n",
      "\u001b[92m[\u001b[0mBNN TL FT\u001b[92m] >> Model Loaded on \u001b[94mcpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "bnn_df_model = copy.deepcopy(bnn_lf_model)\n",
    "bnn_df_model.model_name = \"BNN TL\"\n",
    "model_path_1 = f\"{study_path}/{model_name_prefix}_bnn_tl_2.pt\"\n",
    "model_path_2 = f\"{study_path}/{model_name_prefix}_bnn_tl_finetune_2.pt\"\n",
    "\n",
    "if TRAIN_TL_FLAG:\n",
    "    #FREEZE ALL THE PARAMS IN THE MODEL\n",
    "    bnn_df_model.setModelGradients(False)\n",
    "    all_layers = bnn_df_model.getAllLayersName()\n",
    "    layers_to_unfreeze = all_layers[-4:]\n",
    "    print(\"Unfreezing\",layers_to_unfreeze)\n",
    "    bnn_df_model.setModelGradients(True,layers=layers_to_unfreeze)\n",
    "    #Train with MF\n",
    "    bnn_df_model.train_model(\n",
    "        train_mf,\n",
    "        valid_mf,\n",
    "        n_epochs=8000,\n",
    "        lr=0.001,\n",
    "        restoreBestModel=True,\n",
    "        patience=500,\n",
    "        batch_size = 32,\n",
    "        earlyStopping=True\n",
    "    )\n",
    "    if SAVE_MODEL_FLAG: bnn_df_model.save(model_path_1)\n",
    "else: \n",
    "    bnn_df_model.load(model_path_1)\n",
    "    bnn_df_model_fine_tuned = copy.deepcopy(bnn_df_model) \n",
    "    bnn_df_model_fine_tuned.model_name = \"BNN TL FT\"\n",
    "\n",
    "if TRAIN_TL_FT_FLAG:\n",
    "    bnn_df_model_fine_tuned = copy.deepcopy(bnn_df_model) \n",
    "    bnn_df_model_fine_tuned.model_name = \"BNN TL FT\"\n",
    "    bnn_df_model.setModelGradients(False)\n",
    "    layers_to_unfreeze = all_layers[-2:]\n",
    "    bnn_df_model.setModelGradients(True,layers=layers_to_unfreeze)\n",
    "    bnn_df_model_fine_tuned.train_model(\n",
    "        train_hf+valid_hf,\n",
    "        train_hf+valid_hf,\n",
    "        n_epochs=8000,\n",
    "        lr=0.001,\n",
    "        restoreBestModel=True,\n",
    "        patience=500,\n",
    "        batch_size = 1,\n",
    "        earlyStopping=True\n",
    "    )\n",
    "    if SAVE_MODEL_FLAG: bnn_df_model_fine_tuned.save(model_path_2)\n",
    "else: \n",
    "    bnn_df_model_fine_tuned.load(model_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean, pred_std = bnn_df_model_fine_tuned.predict(test_hf.data[[\"mach\",\"aoa\"]].values,scaler=scaler,output_labels=output_labels,attempt=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
